from typing import List
from uuid import uuid4

from pydantic import BaseModel, Field, field_validator

from resources.prompts import get_prompt_no_context_template, get_prompt_template
from resources.valid_models import VALID_MODELS


class UserMessage(BaseModel):
    """
    Contains user message information.
    """

    session_id: str = Field(pattern=r"^s-.*", description="The session ID.")
    conversation_id: str = Field(
        pattern=r"^conv-.*", description="The conversation ID."
    )
    message_id: str = Field(
        default="user-" + str(uuid4()),
        description="The user message ID. This should not be provided by input.",
    )
    content: str = Field(min_length=1, description="The user's question.")
    embedding: List[float] = Field(description="The user question embedding.")
    role: str = Field(
        default="user", description="The message role. This must be user."
    )
    public: bool = Field(
        description="Whether the question is from the public facing app or not."
    )

    @field_validator("message_id")
    def validate_message_id(cls, v: str) -> str:
        if not v.startswith("user-"):
            raise ValueError(
                "message_id must start with 'user-' followed by a uuid string. This is generated by default and should not be passed as input."
            )
        return v

    @field_validator("role")
    def validate_role(cls, v: str) -> str:
        assert v == "user", "role must equal 'user'."
        return v


class AssistantMessage(BaseModel):
    """
    Contains assistant message information.
    """
    session_id: str = Field(pattern=r"^s-.*", description="The session ID.")
    conversation_id: str = Field(
        pattern=r"^conv-.*", description="The conversation ID."
    )
    message_id: str = Field(
        default="llm-" + str(uuid4()),
        description="The user message ID. This should not be provided by input.",
    )
    prompt: str = Field(
        description="The prompt given to the LLM to generate a response."
    )
    content: str = Field(min_length=1, description="The LLM generated response.")
    role: str = Field(
        default="assistant", description="The message role. This must be 'assistant'."
    )
    public: bool = Field(
        description="Whether the question is from the public facing app or not."
    )
    vector_index_search: bool = Field(
        default=True,
        description="Whether context was gathered with vector index search.",
    )
    number_of_documents: int = Field(
        default=10,
        ge=0,
        le=10,
        description="The number of documents to use as context.",
    )
    temperature: float = Field(
        default=0.0, ge=0.0, le=1.0, description="Temperature parameter for the LLM."
    )

    @field_validator("message_id")
    def validate_message_id(cls, v: str) -> str:
        if not v.startswith("llm-"):
            raise ValueError(
                "message_id must start with 'user-' followed by a uuid string. This is generated by default and should not be passed as input."
            )
        return v

    @field_validator("role")
    def validate_role(cls, v: str) -> str:
        assert v == "assistant", "role must equal 'assistant'."
        return v

    @field_validator("prompt")
    def validate_prompt(cls, v: str) -> str:
        return v


class Conversation(BaseModel):
    """
    Contains conversation information.
    """

    session_id: str = Field(pattern=r"^s-.*", description="The session ID.")
    conversation_id: str = Field(
        pattern=r"^conv-.*", description="The conversation ID."
    )
    llm_type: str = Field(description="The LLM to use for response generation.")

    @field_validator("llm_type")
    def validate_llm_type(cls, v: str) -> str:
        if v.lower() not in VALID_MODELS:
            raise ValueError(
                f"llm_type must be one of the following: {str(VALID_MODELS)}."
            )
        return v.lower()


class Session(BaseModel):
    """
    Contains session information.
    """
    session_id: str = Field(pattern=r"^s-.*", description="The session ID.")


class DocumentNode(BaseModel):
    """
    Contains document (node) information.
    """
    community: int = Field(description="community the node belongs too")
    contextCount: int = Field("context count")
    embedding: list[float] = Field(description="text embedding")
    fast_rp_similarity: list[float] = Field(description="fast-rp similarity")
    index: int = Field(description="index")
    pageRank: float = Field(description="page rank score")
    text: str = Field(description="text chunk")
    url: str = Field(description="url")


class DocumentRelationship(BaseModel):
    start_node: DocumentNode = Field(description="start document node in relationship")
    end_node: DocumentNode = Field(description="end document node in relationship")


class MessageNode(BaseModel):
    """
    Contains Message (node) information.
    """
    content: str = Field(description="message content")
    id: str = Field(description="message id")
    post_time: str = Field(description="post time")  # todo refactor this to a temporal type in the database
    role: str = Field(description="user")


class MessageRelationship(BaseModel):
    start_node: MessageNode = Field(description="start message node in relationship")
    end_node: MessageNode = Field(description="end message node in relationship")


class ConversationEntry(BaseModel):
    """
    Contains the conversation entry information. a conversation entry is both the question/response sequence and the referenced RAG documents.
    """
    document_nodes: List[DocumentNode]
    message_nodes: List[MessageNode]
    document_relationships: List[DocumentRelationship]
    message_relationships: List[MessageRelationship]


