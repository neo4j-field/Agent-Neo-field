{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandergilmore/Documents/GitHub/Agent-Neo-field/venv/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import pandas as pd\n",
    "# sys.path.append(\"/Users/alexandergilmore/Documents/GitHub/Agent-Neo-field/src/main/python/scrape/scraper\")\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from scrape import WebContentChunker\n",
    "from scrape.scraper.embedding import TextEmbeddingService, LangchainEmbeddingService\n",
    "from scrape.scraper.preprocessing import fix_neo4j_spelling, remove_filler_words\n",
    "from neo4jwriter.neo4jwriter import Neo4jWriter\n",
    "from google.cloud import aiplatform, storage\n",
    "from google.oauth2 import service_account\n",
    "from uuid import uuid4\n",
    "import backoff\n",
    "import grpc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_credentials = service_account.Credentials.from_service_account_file(\n",
    "    os.environ.get(\"GCP_SERVICE_ACCOUNT_KEY_PATH\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_service = TextEmbeddingService('textembedding-gecko@001', \n",
    "#                                             aiplatform_client=aiplatform.init(project=os.environ.get('GCP_PROJECT'), \n",
    "#                                             location=os.environ.get('GCP_REGION'), \n",
    "#                                             credentials=google_credentials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex = VertexAIEmbeddings(credentials=google_credentials, \n",
    "                            project=os.environ.get('GCP_PROJECT'), \n",
    "                            location=os.environ.get('GCP_REGION'),\n",
    "                            model_name=\"textembedding-gecko@001\")\n",
    "\n",
    "embedding_service = LangchainEmbeddingService(vertex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_method(lst, batch_size=500):\n",
    "    for i in range(0, len(lst), batch_size):\n",
    "        yield lst[i:i + batch_size]\n",
    "\n",
    "\n",
    "def prepare_new_nodes(data: List, playlist_id: str = \"\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    format chunked data to be uploaded into neo4j graph.\n",
    "    embedding must abide by rate limits: 60 requests / minute\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data)\n",
    "    new_nodes = data.copy()\n",
    "\n",
    "    i = 0\n",
    "    # print(\"total chunks to process: \", total)\n",
    "    for chunk in new_nodes:\n",
    "        \n",
    "\n",
    "            # try:\n",
    "        start = time.time()\n",
    "\n",
    "        # make request\n",
    "        # print(\"batch percent: \", str(round((i+1) / total, 4)*100)[:4], \"%\", \" request\", i+1, end=\"\\r\")\n",
    "        chunk.update({  \"index\": str(uuid4()),\n",
    "                        \"playlist_id\": playlist_id,\n",
    "                        \"embedding\": embedding_service.generate_embedding(chunk['transcript'])})\n",
    "        \n",
    "        stop = time.time()\n",
    "        # abide by rate limit (1 per sec)\n",
    "        while stop - start < 1:\n",
    "            stop = time.time()\n",
    "\n",
    "        i+=1\n",
    "\n",
    "            # except Exception as e:\n",
    "\n",
    "                # if i < try_limit:\n",
    "                #     i+=1\n",
    "                #     time.sleep(i+1)\n",
    "                #     continue\n",
    "                # else:\n",
    "                # print(e)\n",
    "                # return new_nodes, i\n",
    "            \n",
    "    return new_nodes, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scrape/scraper/resources/youtube_playlist_ids.json\") as json_file:\n",
    "    playlists = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Going Meta'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(playlists.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = WebContentChunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to prod cause this seems to work\n",
    "writer = Neo4jWriter(neo4j_password=\"nV-6qhEkZOXfNAcOOD0eUTXLeu-tzEy7bNjTDyv5niY\", \n",
    "                     neo4j_url=\"neo4j+s://9eb79ecf.databases.neo4j.io\")\n",
    "\n",
    "# writer = Neo4jWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "UNWIND $params AS param\n",
    "\n",
    "MERGE (d:Document {index: param.index})\n",
    "MERGE (s:Source {url: param.url})\n",
    "MERGE (t:Type {type: \"YouTube transcript\"})\n",
    "SET\n",
    "    d.createTime = datetime(),\n",
    "    d.text = param.transcript,\n",
    "    d.url = param.url,\n",
    "    d.embedding = param.embedding,\n",
    "    \n",
    "    s.title = param.title,\n",
    "    s.playlist_id = param.playlist_id,\n",
    "    s.video_id = param.video_id,\n",
    "    s.publish_date = param.publish_date\n",
    "    \n",
    "MERGE (d)-[:HAS_SOURCE]->(s)\n",
    "MERGE (s)-[:HAS_TYPE]->(t)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trouble_playlists = {'Going Meta': 'PL9Hl4pk2FsvX-5QPvwChB-ni_mFF97rCE',\n",
    " 'Ask a Data Scientist: Season III': 'PL9Hl4pk2FsvVkj5ZrwtYiiwQVzDB7ZhcC',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going Meta 667\n",
      "grabbing embeddings...\n",
      "chunks processed:  667  batch 34\n",
      "playlist     :  Going Meta\n",
      "failed index :  7\n",
      "loading to graph...\n",
      "playlist upload complete!\n",
      "Nodes 2023 GenAI 116\n",
      "grabbing embeddings...\n",
      "chunks processed:  116  batch 6\n",
      "playlist     :  Nodes 2023 GenAI\n",
      "failed index :  16\n",
      "loading to graph...\n",
      "playlist upload complete!\n",
      "Ask a Data Scientist: Season III 9\n",
      "grabbing embeddings...\n",
      "chunks processed:  9 %  batch 1\n",
      "playlist     :  Ask a Data Scientist: Season III\n",
      "failed index :  9\n",
      "loading to graph...\n",
      "playlist upload complete!\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/2X4ZZGjOtXo\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/5O7wEUrBSLY\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/9zk5hcHV3-I\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/CKMBh3m3UVY\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/KbMHtm3y6PI\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/TU3xpczmHI0\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/ZR0-fkyMaiw\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/ghOGAgth4sI\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Error loading document with id: youtube/transcripts/Ask a Data Scientist: Season III/tQCjf5a7G6E\n",
      "Error: 'NoneType' object has no attribute 'download_as_text'\n",
      "Ask a Data Scientist: Season II 6\n",
      "grabbing embeddings...\n",
      "chunks processed:  6 %  batch 1\n",
      "playlist     :  Ask a Data Scientist: Season II\n",
      "failed index :  6\n",
      "loading to graph...\n",
      "playlist upload complete!\n",
      "Neo4j Aura How to Videos 18\n",
      "grabbing embeddings...\n",
      "chunks processed:  18%  batch 1\n",
      "playlist     :  Neo4j Aura How to Videos\n",
      "failed index :  18\n",
      "loading to graph...\n",
      "playlist upload complete!\n"
     ]
    }
   ],
   "source": [
    "for playlist, pl_id in playlists.items():\n",
    "\n",
    "    chunker._chunked_documents = []\n",
    "    chunker.chunk_youtube_transcripts(playlist_title=playlist,\n",
    "                                  cleaning_functions=[fix_neo4j_spelling, remove_filler_words])\n",
    "    \n",
    "    result = []\n",
    "    failed_idx = None\n",
    "    playlist_total = len(chunker.youtube_chunks_as_list)\n",
    "\n",
    "    print(playlist, playlist_total)\n",
    "    print(\"grabbing embeddings...\")\n",
    "    for idx, batch in enumerate(batch_method(chunker.youtube_chunks_as_list, 20)):\n",
    "        new_nodes, failed_idx = prepare_new_nodes(data=batch, playlist_id=pl_id)\n",
    "        result+=new_nodes\n",
    "        print(\"total percent: \", str(round(((20*idx)+1) / playlist_total, 4)*100)[:4], \"%\", \" batch\", idx+1, end=\"\\r\")\n",
    "\n",
    "    print(\"chunks processed: \", len(result))\n",
    "    if failed_idx is not None:\n",
    "        print(\"playlist     : \", playlist)\n",
    "        print(\"failed index : \", failed_idx)\n",
    "\n",
    "    print(\"loading to graph...\")\n",
    "    writer.batch_write(cypher_query=query, params=result, batch_size=100)\n",
    "\n",
    "    print(\"playlist upload complete!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
